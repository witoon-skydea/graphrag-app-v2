# แผนการทดสอบการใช้งานจริงของ GraphRAG (User Acceptance Test Plan)

## 1. วัตถุประสงค์ของการทดสอบ

แผนการทดสอบนี้มีวัตถุประสงค์เพื่อประเมินประสิทธิภาพและความสามารถในการใช้งานได้จริงของระบบ GraphRAG จากมุมมองของผู้ใช้งานทั่วไป โดยเน้นการทดสอบฟีเจอร์หลักและกระบวนการทำงานตั้งแต่ต้นจนจบ (End-to-End) เพื่อให้แน่ใจว่าระบบสามารถใช้งานได้อย่างมีประสิทธิภาพในสภาพแวดล้อมจริง

วัตถุประสงค์หลัก:
1. ทดสอบการติดตั้งและการตั้งค่าระบบตามคู่มือการใช้งาน
2. ทดสอบการประมวลผลเอกสารประเภทต่างๆ
3. ทดสอบการสร้างและการใช้งาน Knowledge Graph
4. ทดสอบการค้นหาและการสืบค้นข้อมูล
5. ประเมินประสิทธิภาพและความเสถียรของระบบ
6. ประเมินความพึงพอใจของผู้ใช้งาน

## 2. สภาพแวดล้อมและการเตรียมการทดสอบ

### 2.1 อุปกรณ์และระบบที่ใช้ทดสอบ

- **คอมพิวเตอร์**: macOS (M1/M2 Macbook) หรือ Linux (Ubuntu 20.04+)
- **หน่วยความจำ**: อย่างน้อย 16GB RAM
- **พื้นที่ดิสก์**: อย่างน้อย 30GB พื้นที่ว่าง
- **การเชื่อมต่ออินเทอร์เน็ต**: จำเป็นสำหรับการติดตั้ง dependencies และดาวน์โหลดโมเดล

### 2.2 ซอฟต์แวร์ที่ต้องติดตั้ง

- **Python**: เวอร์ชัน 3.8 หรือใหม่กว่า
- **Docker**: เวอร์ชันล่าสุด
- **Ollama**: เวอร์ชันล่าสุด
- **Tesseract OCR**: เวอร์ชันล่าสุด

### 2.3 เอกสารตัวอย่างสำหรับการทดสอบ

เตรียมเอกสารตัวอย่างสำหรับแต่ละประเภทไฟล์:

1. **ไฟล์ TXT**:
   - คู่มือการใช้งาน API (3-5 หน้า)
   - บทความวิชาการ (5-10 หน้า)
   - บันทึกการประชุม (1-2 หน้า)

2. **ไฟล์ DOCX**:
   - เอกสารโครงการ (10-15 หน้า)
   - เอกสารข้อเสนอทางธุรกิจ (5-10 หน้า)
   - ประวัติส่วนตัว/เรซูเม่ (2-3 หน้า)

3. **ไฟล์ PDF (ข้อความ)**:
   - รายงานประจำปี (20-30 หน้า)
   - เอกสารวิชาการ (10-15 หน้า)
   - จดหมายธุรกิจ (1-2 หน้า)

4. **ไฟล์ PDF (รูปภาพ/สแกน)**:
   - เอกสารสแกน (3-5 หน้า)
   - สิ่งพิมพ์ที่มีทั้งข้อความและรูปภาพ (5-10 หน้า)

5. **ไฟล์ CSV/Excel**:
   - ตารางข้อมูลบุคลากร (50-100 รายการ)
   - ข้อมูลสินค้า/ผลิตภัณฑ์ (100-200 รายการ)
   - ข้อมูลงบประมาณ (20-30 รายการ)

หมายเหตุ: ข้อมูลที่ใช้ทดสอบควรมีความหลากหลาย มี entities และความสัมพันธ์ที่เกี่ยวข้องกันในหลายๆ เอกสาร เพื่อทดสอบการสร้างความสัมพันธ์ข้ามเอกสาร (cross-document relationships)

## 3. ขั้นตอนการทดสอบ

### 3.1 การติดตั้งและการตั้งค่า

#### TC-01: การติดตั้งตาม README.md

| Test Case ID | TC-01 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการติดตั้งระบบตามคำแนะนำใน README.md |
| ขั้นตอน | 1. โคลนโปรเจคจาก GitHub<br>2. รันสคริปต์ setup_test_environment.sh<br>3. ตรวจสอบว่าติดตั้ง dependencies ครบถ้วน<br>4. ตรวจสอบว่าซอฟต์แวร์ที่จำเป็น (Ollama, Tesseract OCR) ทำงานได้ |
| ผลที่คาดหวัง | ติดตั้งระบบสำเร็จโดยไม่มีข้อผิดพลาด |
| ระดับความสำคัญ | Critical |

#### TC-02: การตั้งค่า Ollama และโมเดล

| Test Case ID | TC-02 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการตั้งค่า Ollama และดาวน์โหลดโมเดล mxbai-embed-large |
| ขั้นตอน | 1. เริ่มการทำงานของ Ollama<br>2. ดาวน์โหลดโมเดล mxbai-embed-large<br>3. ตรวจสอบว่าโมเดลพร้อมใช้งาน |
| ผลที่คาดหวัง | Ollama ทำงานได้และโมเดล mxbai-embed-large พร้อมใช้งาน |
| ระดับความสำคัญ | Critical |

#### TC-03: การตั้งค่า Weaviate

| Test Case ID | TC-03 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการตั้งค่า Weaviate ด้วย Docker |
| ขั้นตอน | 1. รันคำสั่ง Docker เพื่อเริ่ม Weaviate<br>2. ตรวจสอบว่า Weaviate ทำงานที่พอร์ต 8080<br>3. ตรวจสอบการเข้าถึง Weaviate API |
| ผลที่คาดหวัง | Weaviate ทำงานได้และ API พร้อมใช้งาน |
| ระดับความสำคัญ | Critical |

### 3.2 การประมวลผลเอกสาร

#### TC-04: การประมวลผลไฟล์ TXT

| Test Case ID | TC-04 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการประมวลผลไฟล์ TXT |
| ขั้นตอน | 1. เตรียมไฟล์ TXT ตัวอย่าง<br>2. รันโค้ดสำหรับการประมวลผลไฟล์ TXT<br>3. ตรวจสอบผลลัพธ์เนื้อหาและ metadata |
| ผลที่คาดหวัง | ประมวลผลไฟล์ TXT สำเร็จ สามารถดึงเนื้อหาและ metadata ได้ครบถ้วน |
| ระดับความสำคัญ | High |

#### TC-05: การประมวลผลไฟล์ DOCX

| Test Case ID | TC-05 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการประมวลผลไฟล์ DOCX |
| ขั้นตอน | 1. เตรียมไฟล์ DOCX ตัวอย่าง<br>2. รันโค้ดสำหรับการประมวลผลไฟล์ DOCX<br>3. ตรวจสอบผลลัพธ์เนื้อหาและ metadata |
| ผลที่คาดหวัง | ประมวลผลไฟล์ DOCX สำเร็จ สามารถดึงเนื้อหาและ metadata ได้ครบถ้วน |
| ระดับความสำคัญ | High |

#### TC-06: การประมวลผลไฟล์ PDF (ข้อความ)

| Test Case ID | TC-06 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการประมวลผลไฟล์ PDF ที่มีข้อความ |
| ขั้นตอน | 1. เตรียมไฟล์ PDF ตัวอย่างที่มีข้อความ<br>2. รันโค้ดสำหรับการประมวลผลไฟล์ PDF<br>3. ตรวจสอบผลลัพธ์เนื้อหาและ metadata |
| ผลที่คาดหวัง | ประมวลผลไฟล์ PDF สำเร็จ สามารถดึงเนื้อหาและ metadata ได้ครบถ้วน |
| ระดับความสำคัญ | High |

#### TC-07: การประมวลผลไฟล์ PDF (รูปภาพ) ด้วย OCR

| Test Case ID | TC-07 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการประมวลผลไฟล์ PDF ที่เป็นรูปภาพด้วย OCR |
| ขั้นตอน | 1. เตรียมไฟล์ PDF ตัวอย่างที่เป็นรูปภาพ<br>2. รันโค้ดสำหรับการประมวลผลไฟล์ PDF ด้วย OCR<br>3. ตรวจสอบผลลัพธ์เนื้อหาและความแม่นยำของ OCR |
| ผลที่คาดหวัง | ประมวลผลไฟล์ PDF ด้วย OCR สำเร็จ สามารถแปลงข้อความจากรูปภาพได้อย่างมีประสิทธิภาพ |
| ระดับความสำคัญ | Medium |

#### TC-08: การประมวลผลไฟล์ CSV/Excel

| Test Case ID | TC-08 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการประมวลผลไฟล์ CSV/Excel |
| ขั้นตอน | 1. เตรียมไฟล์ CSV/Excel ตัวอย่าง<br>2. รันโค้ดสำหรับการประมวลผลไฟล์ CSV/Excel<br>3. ตรวจสอบผลลัพธ์เนื้อหาและโครงสร้างข้อมูล |
| ผลที่คาดหวัง | ประมวลผลไฟล์ CSV/Excel สำเร็จ สามารถแปลงโครงสร้างตารางเป็นข้อความและความสัมพันธ์ได้ |
| ระดับความสำคัญ | Medium |

### 3.3 การสร้างและการใช้งาน Knowledge Graph

#### TC-09: การสกัด Entities จากเอกสารเดี่ยวด้วยโมเดล mxbai-embed-large

| Test Case ID | TC-09 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการสกัด entities จากเอกสารเดี่ยวด้วยโมเดล mxbai-embed-large |
| ขั้นตอน | 1. เลือกเอกสารที่มี entities ที่ชัดเจน (เช่น ชื่อบุคคล องค์กร สถานที่)<br>2. รันโค้ดสำหรับการสกัด entities ด้วยโมเดล mxbai-embed-large<br>3. ตรวจสอบผลลัพธ์การสกัด entities |
| ผลที่คาดหวัง | สกัด entities ได้อย่างถูกต้อง มีการระบุประเภทของ entities อย่างชัดเจน |
| ระดับความสำคัญ | High |

#### TC-09B: การสกัด Entities จากเอกสารเดี่ยวด้วยโมเดล gemma3:12b

| Test Case ID | TC-09B |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการสกัด entities จากเอกสารเดี่ยวด้วยโมเดล gemma3:12b |
| ขั้นตอน | 1. เลือกเอกสารที่มี entities ที่ชัดเจน (เช่น ชื่อบุคคล องค์กร สถานที่)<br>2. ตั้งค่า Ollama ให้ใช้โมเดล gemma3:12b<br>3. รันโค้ดสำหรับการสกัด entities ด้วยโมเดล gemma3:12b<br>4. ตรวจสอบผลลัพธ์การสกัด entities และเปรียบเทียบกับผลลัพธ์จากโมเดล mxbai-embed-large |
| ผลที่คาดหวัง | สกัด entities ได้อย่างถูกต้อง มีการระบุประเภทของ entities อย่างชัดเจน และมีความแม่นยำสูงกว่าหรือเทียบเท่ากับโมเดล mxbai-embed-large |
| ระดับความสำคัญ | High |

#### TC-10: การระบุความสัมพันธ์ระหว่าง Entities

| Test Case ID | TC-10 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการระบุความสัมพันธ์ระหว่าง entities ภายในเอกสารเดียวกัน |
| ขั้นตอน | 1. เลือกเอกสารที่มีความสัมพันธ์ระหว่าง entities ที่ชัดเจน<br>2. รันโค้ดสำหรับการระบุความสัมพันธ์<br>3. ตรวจสอบผลลัพธ์ความสัมพันธ์ที่สร้างขึ้น |
| ผลที่คาดหวัง | ระบุความสัมพันธ์ระหว่าง entities ได้อย่างถูกต้อง มีการระบุประเภทความสัมพันธ์อย่างชัดเจน |
| ระดับความสำคัญ | High |

#### TC-11: การประมวลผลเอกสารหลายไฟล์และสร้าง Knowledge Graph รวม

| Test Case ID | TC-11 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการประมวลผลเอกสารหลายไฟล์และสร้าง Knowledge Graph รวม |
| ขั้นตอน | 1. เตรียมเอกสารหลากหลายประเภท (TXT, DOCX, PDF) ที่มีเนื้อหาเกี่ยวข้องกัน<br>2. รันโค้ดสำหรับการประมวลผลเอกสารทั้งหมดพร้อมกัน<br>3. ตรวจสอบ Knowledge Graph ที่สร้างขึ้น |
| ผลที่คาดหวัง | สร้าง Knowledge Graph จากเอกสารหลายไฟล์ได้ มีการเชื่อมโยงความสัมพันธ์ระหว่างเอกสาร |
| ระดับความสำคัญ | Critical |

#### TC-12: การระบุความสัมพันธ์ข้ามเอกสาร (Cross-document Relationships)

| Test Case ID | TC-12 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการระบุความสัมพันธ์ระหว่าง entities ที่อยู่ในเอกสารต่างกัน |
| ขั้นตอน | 1. เตรียมเอกสารหลายไฟล์ที่มี entities เดียวกันหรือเกี่ยวข้องกัน<br>2. รันโค้ดสำหรับการระบุความสัมพันธ์ข้ามเอกสาร<br>3. ตรวจสอบความสัมพันธ์ข้ามเอกสารที่สร้างขึ้น |
| ผลที่คาดหวัง | ระบุความสัมพันธ์ข้ามเอกสารได้อย่างถูกต้อง สามารถเชื่อมโยง entities ที่เกี่ยวข้องกันจากต่างเอกสารได้ |
| ระดับความสำคัญ | High |

### 3.4 การเปรียบเทียบประสิทธิภาพระหว่างโมเดล

#### TC-12A: การเปรียบเทียบความถูกต้องของ Entities ระหว่าง gemma3:12b และ mxbai-embed-large

| Test Case ID | TC-12A |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบเปรียบเทียบความถูกต้องในการสกัด entities ระหว่างโมเดล gemma3:12b และ mxbai-embed-large |
| ขั้นตอน | 1. เลือกชุดเอกสารตัวอย่างที่หลากหลาย<br>2. ประมวลผลเอกสารชุดเดียวกันด้วยทั้งสองโมเดล<br>3. เปรียบเทียบผลลัพธ์ในด้านความถูกต้อง จำนวน entities ที่สกัดได้ และการจำแนกประเภท entities<br>4. วิเคราะห์จุดแข็งและจุดอ่อนของแต่ละโมเดล |
| ผลที่คาดหวัง | สามารถระบุข้อดีข้อเสียของแต่ละโมเดลได้อย่างชัดเจน และระบุสถานการณ์ที่ควรเลือกใช้แต่ละโมเดล |
| ระดับความสำคัญ | High |

#### TC-12B: การเปรียบเทียบความเร็วและการใช้ทรัพยากรระหว่าง gemma3:12b และ mxbai-embed-large

| Test Case ID | TC-12B |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบเปรียบเทียบความเร็วและการใช้ทรัพยากรระหว่างโมเดล gemma3:12b และ mxbai-embed-large |
| ขั้นตอน | 1. เตรียมเอกสารชุดเดียวกัน<br>2. วัดระยะเวลาที่ใช้ในการประมวลผลเอกสารด้วยทั้งสองโมเดล<br>3. วัดการใช้ทรัพยากรระบบ (CPU, RAM) ขณะประมวลผล<br>4. บันทึกและเปรียบเทียบผลลัพธ์ |
| ผลที่คาดหวัง | สามารถระบุได้ว่าโมเดลใดใช้ทรัพยากรน้อยกว่าและทำงานเร็วกว่า เพื่อนำไปใช้ในการตัดสินใจเลือกโมเดลตามสถานการณ์ |
| ระดับความสำคัญ | Medium |

### 3.5 การค้นหาและการสืบค้นข้อมูล

#### TC-13: การค้นหา Entities ตามประเภท

| Test Case ID | TC-13 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการค้นหา entities ตามประเภท |
| ขั้นตอน | 1. สร้าง Knowledge Graph ที่มี entities หลากหลายประเภท<br>2. รันโค้ดสำหรับการค้นหา entities ตามประเภท (เช่น PERSON, ORGANIZATION)<br>3. ตรวจสอบผลลัพธ์การค้นหา |
| ผลที่คาดหวัง | ค้นหา entities ตามประเภทได้อย่างถูกต้อง แสดงผลลัพธ์ครบถ้วน |
| ระดับความสำคัญ | Medium |

#### TC-14: การค้นหา Entities ตามข้อความ

| Test Case ID | TC-14 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการค้นหา entities ตามข้อความ |
| ขั้นตอน | 1. สร้าง Knowledge Graph ที่มี entities หลากหลาย<br>2. รันโค้ดสำหรับการค้นหา entities ตามข้อความ (เช่น ชื่อบางส่วน)<br>3. ตรวจสอบผลลัพธ์การค้นหา |
| ผลที่คาดหวัง | ค้นหา entities ตามข้อความได้อย่างถูกต้อง รองรับการค้นหาแบบ partial match |
| ระดับความสำคัญ | Medium |

#### TC-15: การค้นหาความสัมพันธ์ของ Entity

| Test Case ID | TC-15 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการค้นหาความสัมพันธ์ของ entity |
| ขั้นตอน | 1. สร้าง Knowledge Graph ที่มีความสัมพันธ์หลากหลาย<br>2. รันโค้ดสำหรับการค้นหาความสัมพันธ์ของ entity ที่ระบุ<br>3. ตรวจสอบความสัมพันธ์ขาเข้าและขาออก |
| ผลที่คาดหวัง | ค้นหาความสัมพันธ์ของ entity ได้อย่างถูกต้อง แสดงทั้งความสัมพันธ์ขาเข้าและขาออก |
| ระดับความสำคัญ | High |

#### TC-16: การค้นหาเส้นทางระหว่าง Entities

| Test Case ID | TC-16 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการค้นหาเส้นทางระหว่าง entities |
| ขั้นตอน | 1. สร้าง Knowledge Graph ที่มีความสัมพันธ์เชื่อมโยงหลายระดับ<br>2. รันโค้ดสำหรับการค้นหาเส้นทางระหว่าง entities สองตัว<br>3. ตรวจสอบเส้นทางที่พบ |
| ผลที่คาดหวัง | ค้นหาเส้นทางระหว่าง entities ได้อย่างถูกต้อง สามารถค้นหาเส้นทางที่มีหลายระดับได้ |
| ระดับความสำคัญ | Medium |

### 3.5 การวิเคราะห์และการแสดงผล

#### TC-17: การดูสถิติของ Knowledge Graph

| Test Case ID | TC-17 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการดูสถิติของ Knowledge Graph |
| ขั้นตอน | 1. สร้าง Knowledge Graph ที่มีข้อมูลหลากหลาย<br>2. รันโค้ดสำหรับการดูสถิติ<br>3. ตรวจสอบข้อมูลสถิติที่แสดง |
| ผลที่คาดหวัง | แสดงสถิติของ Knowledge Graph ได้อย่างถูกต้อง ครอบคลุมจำนวน nodes, edges และการกระจายตัวของประเภท |
| ระดับความสำคัญ | Low |

#### TC-18: การส่งออก Knowledge Graph เป็นรูปแบบเครือข่าย

| Test Case ID | TC-18 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการส่งออก Knowledge Graph เป็นรูปแบบเครือข่ายสำหรับการแสดงผล |
| ขั้นตอน | 1. สร้าง Knowledge Graph ที่มีข้อมูลหลากหลาย<br>2. รันโค้ดสำหรับการส่งออกเป็นรูปแบบเครือข่าย<br>3. ตรวจสอบไฟล์ JSON ที่ส่งออก |
| ผลที่คาดหวัง | ส่งออก Knowledge Graph เป็นรูปแบบเครือข่ายได้อย่างถูกต้อง ครบถ้วน |
| ระดับความสำคัญ | Low |

### 3.6 การจัดการข้อมูลและความเสถียร

#### TC-19: การบันทึกและโหลด Knowledge Graph

| Test Case ID | TC-19 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบการบันทึกและโหลด Knowledge Graph |
| ขั้นตอน | 1. สร้าง Knowledge Graph ที่มีข้อมูลหลากหลาย<br>2. บันทึก Knowledge Graph ลงดิสก์<br>3. โหลด Knowledge Graph จากดิสก์<br>4. ตรวจสอบความถูกต้องของข้อมูล |
| ผลที่คาดหวัง | บันทึกและโหลด Knowledge Graph ได้อย่างถูกต้อง ข้อมูลครบถ้วนไม่สูญหาย |
| ระดับความสำคัญ | High |

#### TC-20: การทดสอบความเสถียรกับข้อมูลขนาดใหญ่

| Test Case ID | TC-20 |
|-------------|-------|
| วัตถุประสงค์ | ทดสอบความเสถียรของระบบเมื่อใช้กับข้อมูลขนาดใหญ่ |
| ขั้นตอน | 1. เตรียมเอกสารขนาดใหญ่หรือเอกสารจำนวนมาก (10+ ไฟล์)<br>2. รันโค้ดสำหรับการประมวลผลเอกสารทั้งหมด<br>3. ตรวจสอบการใช้ทรัพยากรระบบและความเสถียร |
| ผลที่คาดหวัง | ระบบสามารถทำงานได้อย่างเสถียรกับข้อมูลขนาดใหญ่ ไม่เกิด memory leak หรือ crash |
| ระดับความสำคัญ | Medium |

## 4. เกณฑ์การประเมินผล

การประเมินผลการทดสอบจะพิจารณาจากปัจจัยต่อไปนี้:

### 4.1 ประสิทธิภาพการทำงาน (Performance)

- **เวลาในการประมวลผล**: เวลาที่ใช้ในการประมวลผลเอกสารแต่ละประเภท
- **การใช้ทรัพยากร**: การใช้ CPU, RAM และพื้นที่ดิสก์
- **ความเร็วในการค้นหา**: เวลาที่ใช้ในการค้นหาข้อมูลจาก Knowledge Graph

### 4.2 ความถูกต้องของข้อมูล (Accuracy)

- **ความถูกต้องในการสกัด entities**: สัดส่วนของ entities ที่สกัดได้ถูกต้องเทียบกับการตรวจสอบด้วยมนุษย์
- **ความถูกต้องในการระบุความสัมพันธ์**: สัดส่วนของความสัมพันธ์ที่ระบุได้ถูกต้องเทียบกับการตรวจสอบด้วยมนุษย์
- **ความถูกต้องในการค้นหา**: ความถูกต้องของผลลัพธ์การค้นหา (precision & recall)

### 4.3 ความเสถียร (Stability)

- **ความเสถียรในการทำงาน**: จำนวนครั้งที่ระบบเกิดข้อผิดพลาดหรือหยุดทำงาน
- **ความเสถียรในการใช้งานต่อเนื่อง**: ความสามารถในการทำงานต่อเนื่องเป็นเวลานาน
- **ความเสถียรกับข้อมูลขนาดใหญ่**: ความสามารถในการรองรับข้อมูลขนาดใหญ่หรือจำนวนมาก

### 4.4 ความง่ายในการใช้งาน (Usability)

- **ความชัดเจนของคู่มือ**: ความเข้าใจง่ายและครบถ้วนของคู่มือการใช้งาน
- **ความยากง่ายในการติดตั้ง**: จำนวนขั้นตอนและความยากง่ายในการติดตั้งและตั้งค่า
- **ความเข้าใจง่ายของ API**: ความเข้าใจง่ายและความสม่ำเสมอของ API

## 5. แบบฟอร์มบันทึกผลการทดสอบ

สำหรับแต่ละ Test Case ให้บันทึกผลการทดสอบในแบบฟอร์มต่อไปนี้:

### แบบฟอร์มบันทึกผลการทดสอบ (Test Case Record)

```
Test Case ID: [TC-XX]
วันที่ทดสอบ: [DD/MM/YYYY]
ผู้ทดสอบ: [ชื่อผู้ทดสอบ]

สภาพแวดล้อมการทดสอบ:
- ระบบปฏิบัติการ: [OS และเวอร์ชัน]
- แรม: [RAM ขนาด]
- CPU: [CPU รุ่น]
- Python เวอร์ชัน: [Python เวอร์ชัน]

ขั้นตอนการทดสอบที่ดำเนินการ:
1. [ขั้นตอนที่ 1]
2. [ขั้นตอนที่ 2]
3. [ขั้นตอนที่ 3]
...

ผลลัพธ์ที่ได้:
[รายละเอียดผลลัพธ์ที่ได้จากการทดสอบ]

การเปรียบเทียบกับผลที่คาดหวัง:
[เปรียบเทียบผลลัพธ์ที่ได้กับผลที่คาดหวัง]

สถานะการทดสอบ:
[ ] ผ่าน (Pass)
[ ] ผ่านบางส่วน (Partial Pass)
[ ] ไม่ผ่าน (Fail)

ข้อสังเกตและปัญหาที่พบ:
[รายละเอียดข้อสังเกตหรือปัญหาที่พบระหว่างการทดสอบ]

ข้อเสนอแนะในการปรับปรุง:
[ข้อเสนอแนะสำหรับการปรับปรุงระบบ]
```

## 6. ระยะเวลาการทดสอบ

แผนการทดสอบนี้ควรใช้เวลาประมาณ 2-3 วันทำการ โดยแบ่งเป็น:

- **วันที่ 1**: การติดตั้งและการตั้งค่า, การประมวลผลเอกสารเบื้องต้น
- **วันที่ 2**: การสร้างและใช้งาน Knowledge Graph, การค้นหาและสืบค้นข้อมูล
- **วันที่ 3**: การทดสอบความเสถียรและประสิทธิภาพ, การรวบรวมผลและสรุปผลการทดสอบ

## 7. สรุปผลการทดสอบ

เมื่อดำเนินการทดสอบเสร็จสิ้น ให้จัดทำรายงานสรุปผลการทดสอบ ประกอบด้วย:

1. **ภาพรวมของการทดสอบ**: จำนวน Test Cases ที่ผ่าน/ไม่ผ่าน/ผ่านบางส่วน
2. **สรุปปัญหาที่พบ**: รายการปัญหาที่พบและระดับความรุนแรง
3. **ประเมินประสิทธิภาพโดยรวม**: ประสิทธิภาพโดยรวมของระบบในด้านต่างๆ
4. **ข้อเสนอแนะในการปรับปรุง**: ข้อเสนอแนะสำหรับการปรับปรุงระบบในอนาคต
5. **ความพึงพอใจของผู้ใช้งาน**: ระดับความพึงพอใจของผู้ใช้งานต่อระบบโดยรวม

รายงานสรุปผลการทดสอบจะเป็นข้อมูลสำคัญสำหรับการปรับปรุงและพัฒนาระบบ GraphRAG ในเวอร์ชันต่อไป